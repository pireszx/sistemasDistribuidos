# Pool de Threads em Sistemas Distribuídos

> Resumo

Este README reúne conceitos, práticas e recomendações para projetar, dimensionar e operar *thread pools* (piscinas de threads) em sistemas distribuídos. O foco é prático: evitar armadilhas comuns, garantir observabilidade e alinhar a configuração à natureza do workload (CPU-bound vs I/O-bound).

---

## Sumário

1. [O que é um thread pool](#o-que-%C3%A9-um-thread-pool)
2. [Por que usar pools de threads em sistemas distribuídos](#por-que-usar-pools-de-threads-em-sistemas-distribu%C3%ADdos)
3. [Tipos comuns de pools e filas](#tipos-comuns-de-pools-e-filas)
4. [Componentes configuráveis](#componentes-configur%C3%A1veis)
5. [Como dimensionar o pool](#como-dimensionar-o-pool)
6. [Problemas e armadilhas (anti-padrões)](#problemas-e-armadilhas-anti-padr%C3%B5es)
7. [Considerações específicas para sistemas distribuídos](#considera%C3%A7%C3%B5es-espec%C3%ADficas-para-sistemas-distribu%C3%ADdos)
8. [Integração com modelos concorrentes modernos](#integra%C3%A7%C3%A3o-com-modelos-concorrentes-modernos)
9. [Boas práticas — checklist](#boas-pr%C3%A1ticas--checklist)
10. [Exemplo prático em Java (`ThreadPoolExecutor`)](#exemplo-pr%C3%A1tico-em-java-threadpoolexecutor)
11. [Diagrama simples (fluxo)](#diagrama-simples-fluxo)
12. [Como medir e ajustar](#como-medir-e-ajustar)
13. [Referências e leitura adicional](#refer%C3%AAncias-e-leitura-adicional)
14. [Conclusão](#conclus%C3%A3o)

---

## O que é um thread pool

Um *thread pool* é um conjunto reutilizável de threads que aguardam pela execução de tarefas (jobs). Em vez de criar e destruir threads por requisição, os workers do pool são reaproveitados, reduzindo overhead de criação, latência de atendimento e riscos de esgotamento de recursos.

---

## Por que usar pools de threads em sistemas distribuídos

* **Redução de latência** (evita custo de criação/destruição frequente).
* **Controle de recursos** (limita quantas tarefas são executadas em paralelo por nó).
* **Mecanismos de backpressure** por meio de filas e políticas de rejeição.
* **Maior previsibilidade** de comportamento sob pico.

---

## Tipos comuns de pools e filas

* **Fixed / Bounded pool**: número fixo de threads + fila (size limitada). Bom para previsibilidade.
* **Cached / Unbounded**: expande conforme demanda; atenção: pode criar muitas threads e esgotar CPU/memória.
* **ForkJoin / Work-stealing**: ideal para tarefas recursivas e CPU-bound que se subdividem; melhora balanceamento automático.
* **Synchronous / direct-handoff** (ex.: `SynchronousQueue`): não enfileira — entrega direta para thread livre; útil para cenários onde queremos evitar filas longas.

---

## Componentes configuráveis

* `corePoolSize` / `maximumPoolSize` — mínimo/máximo de threads.
* `work queue` — tipo (bounded/unbounded/direct handoff) e tamanho.
* `rejection policy` — como tratar tarefas quando o pool/queue está saturado (Abort, CallerRuns, Discard, DiscardOldest, custom).
* `keepAlive` — tempo de vida de threads ociosas acima do core.

---

## Como dimensionar o pool

* **CPU-bound**: `N_threads ≈ N_cpu` (núcleos ou vCPUs) — evitar oversubscription.
* **I/O-bound**: pode-se ter muito mais threads do que núcleos (threads esperam I/O). Uma fórmula prática:

```
N_threads = N_cpu * (1 + WaitTime/ServiceTime)
```

onde `WaitTime/ServiceTime` é a razão entre tempo gasto esperando (I/O) e tempo gast o processando (CPU).

* **Medir no ambiente real** é obrigatório — regras de polegar falham em produção.

---

## Problemas e armadilhas (anti-padrões)

* **Fila infinita + threads limitadas**: aceita tudo e aumenta latência indefinidamente (degradação silenciosa).
* **Pool global para tudo**: mistura I/O, CPU e manutenção; causa *head-of-line blocking*.
* **Ignorar política de rejeição**: faz o sistema falhar silenciosamente ou perder requests.

---

## Considerações específicas para sistemas distribuídos

1. **Backpressure & circuit breakers**: aplique limites no gateway ou no ponto de entrada e use circuit breakers para evitar sobrecarregar serviços downstream.
2. **Pools separados por tipo**: um pool para I/O bloqueante (DB/HTTP), outro para processamento CPU-bound.
3. **Time-outs e cancelamento**: impor deadlines em tarefas para liberar threads.
4. **Observabilidade**: métricas como `activeThreads`, `queueSize`, `taskWaitTime`, `rejectionCount` são essenciais.
5. **Considerar a topologia de cluster / NUMA**: configurar levando em conta número de processos por nó e afinidade de CPU (quando aplicável).

---

## Integração com modelos concorrentes modernos

* **Ator / message-passing (ex.: Akka, Erlang)**: atores executam sobre dispatchers (pools). O uso de atores reduz a necessidade de locks, mas ainda depende de pools bem configurados.
* **Work-stealing (ForkJoin)**: ótimo para tarefas subdivididas e CPU-bound; ruim para workloads muito bloqueantes (I/O).

---

## Boas práticas — checklist

* Separe pools por tipo de trabalho (I/O vs CPU vs manutenção).
* Use filas limitadas para evitar degradação silenciosa.
* Configure e teste uma `rejection policy` apropriada (ex.: `CallerRuns` pode aliviar picos).
* Meça: percentis de latência, tempo médio na fila, contagem de rejeições.
* Considere alternativas reativas (non-blocking I/O) para workloads predominantemente I/O.
* Proteja entradas com rate-limiting e circuit breakers.

---

## Exemplo prático em Java (`ThreadPoolExecutor`)

```java
import java.util.concurrent.*;

public class ThreadPoolExample {
    public static void main(String[] args) throws InterruptedException {
        int corePoolSize = 4;                // número mínimo de threads
        int maximumPoolSize = 20;            // número máximo de threads
        long keepAlive = 60L;                // segundos
        int queueSize = 100;                 // tamanho da fila

        ThreadPoolExecutor executor = new ThreadPoolExecutor(
            corePoolSize,
            maximumPoolSize,
            keepAlive,
            TimeUnit.SECONDS,
            new ArrayBlockingQueue<>(queueSize),
            new ThreadPoolExecutor.CallerRunsPolicy() // política de rejeição
        );

        // Submeter tarefas
        for (int i = 0; i < 1000; i++) {
            final int id = i;
            executor.submit(() -> {
                // Simula trabalho (I/O ou CPU)
                try {
                    Thread.sleep(100); // substituir por I/O/processing real
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                System.out.println("Task " + id + " done by " + Thread.currentThread().getName());
            });

            // Exemplo simples de observabilidade (não em produção)
            if (i % 100 == 0) {
                System.out.printf("Active: %d, Queue: %d, Completed: %d\n",
                        executor.getActiveCount(), executor.getQueue().size(), executor.getCompletedTaskCount());
            }
        }

        executor.shutdown();
        executor.awaitTermination(5, TimeUnit.MINUTES);
    }
}
```

> Observação: ajuste `corePoolSize`, `maximumPoolSize` e `queueSize` conforme workload e capacidade do nó. Use métricas reais para calibrar.

---

## Diagrama simples (fluxo)

```
Cliente ---> [Gateway / Rate Limiter] ---> [Fila de Entrada] ---> +------------------------+
                                                  |                | Pool I/O | Pool CPU |
                                                  v                +------------------------+
                                            (Dispatcher) ---> Workers (executam tasks)
```

---

## Como medir e ajustar

1. **Colete métricas**: active threads, queue size, task wait time, completed tasks, rejection count, latência de requisição (percentis).
2. **Simule carga real** com ferramentas de stress/bench (ex.: JMeter, Locust).
3. **Ajuste incrementalmente**: altere um parâmetro por vez e compare métricas.
4. **Evite otimizações prematuras**: foque em observabilidade antes de tunar.

---

## Referências e leitura adicional

(Procure documentação oficial da linguagem/stack que você usa — ex.: Java `ThreadPoolExecutor`, documentação de frameworks reativos, artigos de engenharia de sites de tecnologia — para guias de produção e estudos de caso.)

---

## Conclusão

Pools de threads são essenciais para controlar concorrência e recursos em sistemas distribuídos. O sucesso depende menos de fórmulas mágicas e mais de escolhas conscientes (separar tipos de workload, filas limitadas, política de rejeição) e de instrumentação para ajustar a configuração com base em medições reais.


